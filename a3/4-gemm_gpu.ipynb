{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# GEMM on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IcE4c-V5Psg"
      },
      "source": [
        "## 1. Set-up "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMbgGWP75Psg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f94ae8-cbb1-4ac8-ff5d-1638df4c15f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "REpyYw1o5Psi"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/drive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username    \n",
        "with open('/content/drive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xmVrYXr05Psi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00264b60-a93d-44a0-f216-009fb2467346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/ece5545’: File exists\n",
            "/content/drive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-NamanMakkar' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/ece5545/a3-NamanMakkar\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 847 bytes | 1024 bytes/s, done.\n",
            "From https://github.com/ML-HW-SYS/a3-NamanMakkar\n",
            "   6e3ad80..f71d951  main       -> origin/main\n",
            "Updating 6e3ad80..f71d951\n",
            "Fast-forward\n",
            " src/ops.py | 3 \u001b[32m+++\u001b[m\n",
            " 1 file changed, 3 insertions(+)\n",
            "/content/drive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/drive/MyDrive/ece5545\n",
        "%cd /content/drive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/drive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/drive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/drive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ll4LScr_5Psi"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WdiSdTlu5Psj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdec2025-fd4e-4748-f100-cdfa8252921f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-conv1d_cpu.ipynb   4-gemm_gpu.ipynb\t    README.md\n",
            "2-conv1d_gpu.ipynb   5-conv2d_dw_gpu.ipynb  src\n",
            "3-conv1d_fpga.ipynb  leaderboard_id.txt     tests\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJDlW3_V5uX8"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VkqX6TEG5tz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb16643-c1e5-43bd-c80a-7f02483f205f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.12.dev/tlcpack_nightly_cu102-0.13.dev42%2Bga6f6f1100-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.10.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (6.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (2.2.1)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (5.9.4)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (22.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Installing collected packages: tlcpack-nightly-cu102\n",
            "Successfully installed tlcpack-nightly-cu102-0.13.dev42+ga6f6f1100\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16GZ_We05Psj"
      },
      "source": [
        "## 3. Implement `make_conv1d_gpu_scheduler_func` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
        "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then \n",
        "$$\n",
        "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
        "$$\n",
        "\n",
        "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
        "\n",
        "The `make_conv1d_gpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array. \n",
        "You should return both the TVM scheduler and the TVM opterator for \n",
        "1. Input $x$\n",
        "2. Input $y$\n",
        "3. Output $out$\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$. \n",
        "Please see the following cells for usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2nIPEBHF5Psj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed633631-8099-4892-f0ab-4da9d97a7eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: [[504.69336 512.46545 493.93903 ... 510.84012 509.8555  514.19006]\n",
            " [523.47076 525.4437  504.1851  ... 521.49854 517.2589  519.2721 ]\n",
            " [507.28436 523.9327  492.32886 ... 510.99527 515.9947  517.83777]\n",
            " ...\n",
            " [513.4128  519.89795 494.37585 ... 522.6633  513.0862  516.14343]\n",
            " [524.838   534.55347 507.97308 ... 532.16895 532.1095  533.21375]\n",
            " [514.8642  542.1322  505.2583  ... 524.63324 525.8705  529.6918 ]]\n",
            "Output: [[504.69363 512.46594 493.93878 ... 510.8406  509.85538 514.19037]\n",
            " [523.4706  525.4435  504.18497 ... 521.4987  517.2591  519.2724 ]\n",
            " [507.28412 523.93286 492.3288  ... 510.9955  515.9947  517.8378 ]\n",
            " ...\n",
            " [513.4127  519.898   494.3758  ... 522.6635  513.0858  516.143  ]\n",
            " [524.83826 534.55383 507.97324 ... 532.16895 532.109   533.21387]\n",
            " [514.8643  542.1324  505.25867 ... 524.6327  525.8708  529.6917 ]]\n",
            "1DConv TVM: 6.358848 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_gemm_gpu_scheduler\n",
        "import os\n",
        "import tvm\n",
        "from tvm import te\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N) \n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"1DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bjnf_oPi5Psk",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac11db8e-8af3-4b05-d367-003a65f35780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 2048), \"float32\"), B: T.Buffer((2048, 512), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 32)\n",
            "        A_local = T.allocate([32], \"float32\", \"local\")\n",
            "        B_local = T.allocate([32], \"float32\", \"local\")\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 16)\n",
            "        threadIdx_x = T.env_thread(\"threadIdx.x\")\n",
            "        threadIdx_y = T.env_thread(\"threadIdx.y\")\n",
            "        C_1 = T.Buffer((524288,), data=C.data)\n",
            "        with T.launch_thread(threadIdx_x, 32):\n",
            "            T.launch_thread(threadIdx_y, 32)\n",
            "            C_1[blockIdx_y * 16384 + threadIdx_y * 512 + blockIdx_x * 32 + threadIdx_x] = T.float32(0)\n",
            "        for k_outer in range(64):\n",
            "            A_local_1 = T.Buffer((32,), data=A_local, scope=\"local\")\n",
            "            for ax1 in range(32):\n",
            "                A_1 = T.Buffer((2097152,), data=A.data)\n",
            "                A_local_1[ax1] = A_1[blockIdx_y * 65536 + threadIdx_y * 2048 + k_outer * 32 + ax1]\n",
            "            B_local_1 = T.Buffer((32,), data=B_local, scope=\"local\")\n",
            "            for ax0 in range(32):\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                B_local_1[ax0] = B_1[k_outer * 16384 + ax0 * 512 + blockIdx_x * 32 + threadIdx_x]\n",
            "            for k_inner in range(32):\n",
            "                T.launch_thread(threadIdx_x, 32)\n",
            "                T.launch_thread(threadIdx_y, 32)\n",
            "                C_1[blockIdx_y * 16384 + threadIdx_y * 512 + blockIdx_x * 32 + threadIdx_x] = C_1[blockIdx_y * 16384 + threadIdx_y * 512 + blockIdx_x * 32 + threadIdx_x] + A_local_1[k_inner] * B_local_1[k_inner]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VQiasz7n5Psk",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333e733a-7d42-4663-9ad2-1b5a7e9fddd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ece5545/a3-NamanMakkar\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.9.16, pytest-7.2.2, pluggy-1.0.0\n",
            "rootdir: /content/drive/MyDrive/ece5545/a3-NamanMakkar\n",
            "plugins: anyio-3.6.2\n",
            "collected 20 items                                                             \u001b[0m\n",
            "\n",
            "tests/test_gemm_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================= \u001b[32m\u001b[1m20 passed\u001b[0m\u001b[32m in 18.07s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_gemm_gpu.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ryvxva8uFTU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}