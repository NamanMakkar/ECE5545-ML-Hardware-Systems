{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# Depthwise-seperable 2D Convolution on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD2GHA5WVSow"
      },
      "source": [
        "## 1. Set-up "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnmfRsiBVSow",
        "outputId": "ed502f0e-590c-4257-f499-78a2353201ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rR5CmYuCVSox"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/drive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username    \n",
        "with open('/content/drive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZHBLuQfVSox",
        "outputId": "ee00ba2b-55e8-47c7-c99e-612f75b9ab65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/ece5545’: File exists\n",
            "/content/drive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-NamanMakkar' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/ece5545/a3-NamanMakkar\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 871 bytes | 1024 bytes/s, done.\n",
            "From https://github.com/ML-HW-SYS/a3-NamanMakkar\n",
            "   bc7521a..6e3ad80  main       -> origin/main\n",
            "Updating bc7521a..6e3ad80\n",
            "Fast-forward\n",
            " src/ops.py | 8 \u001b[32m++++++++\u001b[m\n",
            " 1 file changed, 8 insertions(+)\n",
            "/content/drive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/drive/MyDrive/ece5545\n",
        "%cd /content/drive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/drive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/drive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/drive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfJNPVatVSox",
        "outputId": "41aed894-3021-4beb-f502-dccf8298a13f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Bztq-VVSoy",
        "outputId": "bfb7acb1-8054-4056-fe8f-81b883933b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-conv1d_cpu.ipynb   4-gemm_gpu.ipynb\t    README.md\n",
            "2-conv1d_gpu.ipynb   5-conv2d_dw_gpu.ipynb  src\n",
            "3-conv1d_fpga.ipynb  leaderboard_id.txt     tests\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EghxXWHSVyZR"
      },
      "source": [
        "## 2 Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phf10Wb1VxoB",
        "outputId": "c8944041-ddf5-4c37-c9e6-b20eff3fd803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.12.dev/tlcpack_nightly_cu102-0.13.dev42%2Bga6f6f1100-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (5.9.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (2.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.10.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (6.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (22.2.0)\n",
            "Installing collected packages: tlcpack-nightly-cu102\n",
            "Successfully installed tlcpack-nightly-cu102-0.13.dev42+ga6f6f1100\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1dTOTtqVSoy"
      },
      "source": [
        "## 3. Implement `make_dwsp_conv2d_gpu_scheduler` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 2D convolution and use TVM to optimize it.\n",
        "Please use zero padding and unit stride. \n",
        "You can assume kernel size to be an odd number.\n",
        "The padding will equals to kernel size minus ones.\n",
        "In this case, the output image will preserve the input image dimension.\n",
        "\n",
        "The `make_dwsp_conv2d_gpu_scheduler` takes following arguments:\n",
        "1. Batch size $B$;\n",
        "2. Input channel size $C$;\n",
        "3. Input image height $H$;\n",
        "4. Input image width $W$;\n",
        "5. Output number of channels $O$;\n",
        "6. Kernel size $K$\n",
        "\n",
        "You should return both the TVM scheduler and the TVM opterator for \n",
        "1. Input tensor $x$ with size (B, C, H, W)\n",
        "2. Input kernel weight $y$ with size (O, 1, K, K)\n",
        "3. Output $out$ with size (B, O, H, W)\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$. \n",
        "Please see the following cells the usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rbp2mmTVSoz",
        "outputId": "cf351912-c281-4274-812e-35ff7ddab388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output: [[[[ 5.992046   6.6133723  6.767883  ...  7.879144   6.1353607\n",
            "     5.5820565]\n",
            "   [ 7.0219145  7.1709795  7.787781  ...  8.748227   7.108428\n",
            "     6.759547 ]\n",
            "   [ 7.164562   7.8462653  8.829841  ...  9.635308   8.22555\n",
            "     6.439999 ]\n",
            "   ...\n",
            "   [ 5.41565    8.350394   8.997432  ...  9.640601   7.5656223\n",
            "     5.4365196]\n",
            "   [ 5.357828   7.3932004  7.518719  ...  7.3347936  6.2817135\n",
            "     5.290862 ]\n",
            "   [ 3.2647572  4.66572    5.8500423 ...  5.6427293  4.828835\n",
            "     3.5719402]]\n",
            "\n",
            "  [[ 4.8873014  4.392408   5.7115483 ...  3.3302038  2.800436\n",
            "     3.0503962]\n",
            "   [ 5.376614   5.626443   6.020023  ...  4.2395353  3.5958667\n",
            "     3.3231676]\n",
            "   [ 5.586133   6.6196575  7.3366265 ...  4.799673   4.5222287\n",
            "     5.0465994]\n",
            "   ...\n",
            "   [ 5.336596   6.968148   9.311557  ...  7.370347   5.598652\n",
            "     4.276941 ]\n",
            "   [ 5.571346   6.8386207  7.4686933 ...  6.6963224  5.078533\n",
            "     4.226414 ]\n",
            "   [ 3.931772   4.624997   5.9025626 ...  5.239812   4.5820704\n",
            "     3.3875384]]\n",
            "\n",
            "  [[ 4.0319195  5.330878   5.5825906 ...  5.627939   5.8819995\n",
            "     3.6400335]\n",
            "   [ 5.9827943  6.381275   8.309661  ...  6.9200273  5.740364\n",
            "     5.1534233]\n",
            "   [ 7.3334312  8.544249  10.286138  ...  8.299509   7.7676115\n",
            "     6.5647197]\n",
            "   ...\n",
            "   [ 6.079004   7.5637317 10.173755  ...  9.583274   7.760749\n",
            "     7.207141 ]\n",
            "   [ 4.5457463  7.130425   8.23647   ...  8.323525   6.0184965\n",
            "     6.0765715]\n",
            "   [ 4.8268156  6.13738    7.5817895 ...  6.2131925  5.3756266\n",
            "     4.532133 ]]\n",
            "\n",
            "  [[ 4.6332307  5.962104   5.3364263 ...  6.4030056  4.3718033\n",
            "     3.4740207]\n",
            "   [ 4.546487   5.6514225  6.6360617 ...  6.2650456  4.4312406\n",
            "     4.321054 ]\n",
            "   [ 6.17103    8.152753   7.9823885 ...  9.225574   6.1998816\n",
            "     5.665023 ]\n",
            "   ...\n",
            "   [ 4.8616586  6.9238043  7.812226  ...  7.5612316  7.2651024\n",
            "     5.5547833]\n",
            "   [ 3.5598843  5.3182874  5.3846197 ...  7.843768   6.4416614\n",
            "     5.287841 ]\n",
            "   [ 2.177793   3.900896   3.7471592 ...  5.088484   4.445491\n",
            "     3.9621327]]]\n",
            "\n",
            "\n",
            " [[[ 5.66782    6.542      6.953969  ...  8.754018   7.266997\n",
            "     4.8483367]\n",
            "   [ 7.11477    7.225534   8.456733  ...  9.358242   7.2863855\n",
            "     6.4376764]\n",
            "   [ 8.532063   8.966035   9.376023  ... 10.637289   8.295606\n",
            "     7.6419024]\n",
            "   ...\n",
            "   [ 6.810421   6.793624   8.547359  ...  9.274255   7.1670837\n",
            "     5.7569056]\n",
            "   [ 5.1369348  6.0274315  6.5932612 ...  8.688201   6.525081\n",
            "     5.168476 ]\n",
            "   [ 3.8998435  4.518644   6.182943  ...  5.57988    5.2673855\n",
            "     4.137966 ]]\n",
            "\n",
            "  [[ 4.4908767  5.0529556  6.858596  ...  5.9572086  4.6986113\n",
            "     3.632907 ]\n",
            "   [ 4.4957514  5.6415854  8.034459  ...  7.0385556  6.290038\n",
            "     4.572262 ]\n",
            "   [ 5.91981    5.531421   8.545286  ...  7.689105   6.710326\n",
            "     6.2229733]\n",
            "   ...\n",
            "   [ 6.876158   8.209618   8.798548  ...  8.692977   7.34795\n",
            "     5.6536474]\n",
            "   [ 4.7813025  6.222948   8.266972  ...  7.1593795  7.076433\n",
            "     5.8198385]\n",
            "   [ 4.637736   5.163184   4.678448  ...  6.549253   5.8087425\n",
            "     4.847509 ]]\n",
            "\n",
            "  [[ 5.1269794  5.2893133  6.2322617 ...  7.699815   6.991045\n",
            "     4.2775826]\n",
            "   [ 5.638314   7.422341   7.8404884 ...  9.888711   8.863908\n",
            "     6.114885 ]\n",
            "   [ 6.678749   6.6150475 10.662583  ... 11.857226  10.007011\n",
            "     7.749592 ]\n",
            "   ...\n",
            "   [ 4.493805   6.8905272  8.505458  ...  9.700311   8.886929\n",
            "     7.1450396]\n",
            "   [ 4.5389786  5.4864163  6.8563495 ...  7.069562   7.5516777\n",
            "     6.2142677]\n",
            "   [ 3.146054   4.6259193  4.816448  ...  5.8276844  4.5148516\n",
            "     4.9610534]]\n",
            "\n",
            "  [[ 3.951158   5.8608203  6.0127587 ...  5.4652824  5.1532736\n",
            "     4.9090796]\n",
            "   [ 4.4643216  5.8994546  7.4230237 ...  7.290181   6.0133533\n",
            "     4.1541176]\n",
            "   [ 5.8376565  7.715257   9.402597  ...  9.0971365  8.590046\n",
            "     5.7873282]\n",
            "   ...\n",
            "   [ 5.227652   6.682986   6.2589407 ...  6.9757614  6.0730467\n",
            "     4.3977423]\n",
            "   [ 4.1416435  6.0721383  6.0919104 ...  6.003194   5.2959065\n",
            "     3.504562 ]\n",
            "   [ 3.8292181  5.094248   4.59804   ...  4.663568   4.1188245\n",
            "     2.748297 ]]]\n",
            "\n",
            "\n",
            " [[[ 4.000665   4.6340337  4.907272  ...  6.8154507  5.0565376\n",
            "     3.805952 ]\n",
            "   [ 4.801796   5.094324   6.7896485 ...  7.3811026  6.08766\n",
            "     4.085369 ]\n",
            "   [ 6.013567   6.1264772  8.287334  ...  8.817919   6.6118298\n",
            "     5.4895487]\n",
            "   ...\n",
            "   [ 7.1204605  8.25295   10.306236  ...  8.044431   5.40911\n",
            "     4.874195 ]\n",
            "   [ 6.120344   7.8448606  7.9670095 ...  7.0988917  4.807084\n",
            "     4.397279 ]\n",
            "   [ 4.725907   5.938142   6.567211  ...  5.691508   4.516153\n",
            "     3.6517177]]\n",
            "\n",
            "  [[ 3.019069   3.6465104  4.751412  ...  5.3180943  4.079753\n",
            "     3.2929087]\n",
            "   [ 4.2484183  4.7046013  6.409943  ...  6.3818984  4.4259734\n",
            "     3.5951529]\n",
            "   [ 4.241502   5.6221514  6.763386  ...  7.9610214  6.0832515\n",
            "     5.079136 ]\n",
            "   ...\n",
            "   [ 6.3741627  6.102378   7.354677  ...  5.9398403  5.811672\n",
            "     4.601462 ]\n",
            "   [ 5.271662   5.392538   6.8221726 ...  6.338902   5.1629615\n",
            "     4.545422 ]\n",
            "   [ 4.24914    5.0945945  5.403859  ...  5.057735   4.266851\n",
            "     3.6694252]]\n",
            "\n",
            "  [[ 3.3578513  4.197206   5.1769457 ...  5.4413633  5.0996737\n",
            "     3.4786944]\n",
            "   [ 4.3113217  5.097858   7.607103  ...  7.5720377  6.6649265\n",
            "     4.882815 ]\n",
            "   [ 4.727987   7.180536   8.909705  ...  8.816191   7.282482\n",
            "     6.6501293]\n",
            "   ...\n",
            "   [ 6.7004113  8.036214  10.065129  ...  9.616502   9.184258\n",
            "     7.242375 ]\n",
            "   [ 5.96812    6.85004    9.420367  ...  7.5953608  7.7004323\n",
            "     5.6344543]\n",
            "   [ 5.0711384  6.09027    8.0024805 ...  6.161799   5.466341\n",
            "     4.4332023]]\n",
            "\n",
            "  [[ 4.6747103  4.9516234  5.255894  ...  7.644413   5.175353\n",
            "     4.7154965]\n",
            "   [ 4.8042097  5.0865116  5.707068  ...  7.1374593  6.024611\n",
            "     5.0930524]\n",
            "   [ 6.4434705  8.508569   7.3877974 ...  9.39421    7.386942\n",
            "     5.503575 ]\n",
            "   ...\n",
            "   [ 4.897722   6.419341   7.1654153 ...  7.9125743  7.2348022\n",
            "     5.6423893]\n",
            "   [ 4.3386884  5.7768617  5.983321  ...  6.1041546  6.7123976\n",
            "     4.2975655]\n",
            "   [ 3.3713608  4.3211265  4.6332765 ...  4.7527575  5.4214053\n",
            "     2.9220102]]]]\n",
            "2DConv TVM: 0.103679 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import tvm\n",
        "from tvm import te\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_dwsp_conv2d_gpu_scheduler\n",
        "\n",
        "B = 3\n",
        "C = 4\n",
        "H = 16\n",
        "W = 32\n",
        "#O = C\n",
        "K = 7\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(B, C, H, W).astype(dtype)\n",
        "w_np = np.random.rand(C, 1, K, K).astype(dtype)\n",
        "\n",
        "s, inp, ker, out = make_dwsp_conv2d_gpu_scheduler(B, C, H, W, K) \n",
        "func = tvm.build(s, [inp, ker, out], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((B, C, H, W), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "print(\"Output:\", b)\n",
        "print(f\"2DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtM-xfNHVSoz",
        "outputId": "2e4bf9ea-0717-4d0d-f195-2a79fa2bc3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), out: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
            "        padded_inp = T.allocate([10032], \"float32\", \"global\")\n",
            "        padded_inp_1 = T.Buffer((10032,), data=padded_inp)\n",
            "        for i0, i1 in T.grid(3, 4):\n",
            "            blockIdx_z = T.launch_thread(\"blockIdx.z\", 6)\n",
            "            blockIdx_y = T.launch_thread(\"blockIdx.y\", 10)\n",
            "            threadIdx_z = T.launch_thread(\"threadIdx.z\", 4)\n",
            "            threadIdx_y = T.launch_thread(\"threadIdx.y\", 4)\n",
            "            if T.likely(blockIdx_z * 2 + threadIdx_z // 2 < 11):\n",
            "                if T.likely(blockIdx_y * 2 + threadIdx_y // 2 < 19):\n",
            "                    A_1 = T.Buffer((6144,), data=A.data)\n",
            "                    padded_inp_1[i0 * 3344 + i1 * 836 + blockIdx_z * 152 + threadIdx_z * 38 + blockIdx_y * 4 + threadIdx_y] = T.if_then_else(blockIdx_z * 4 + threadIdx_z < 3 or 19 <= blockIdx_z * 4 + threadIdx_z or blockIdx_y * 4 + threadIdx_y < 3 or 35 <= blockIdx_y * 4 + threadIdx_y, T.float32(0), A_1[i0 * 2048 + i1 * 512 + blockIdx_z * 128 + threadIdx_z * 32 + blockIdx_y * 4 + threadIdx_y - 99])\n",
            "        for b, c in T.grid(3, 4):\n",
            "            blockIdx_x = T.launch_thread(\"blockIdx.x\", 4)\n",
            "            blockIdx_y = T.launch_thread(\"blockIdx.y\", 8)\n",
            "            threadIdx_x = T.launch_thread(\"threadIdx.x\", 4)\n",
            "            threadIdx_y = T.launch_thread(\"threadIdx.y\", 4)\n",
            "            out_1 = T.Buffer((6144,), data=out.data)\n",
            "            out_1[b * 2048 + c * 512 + blockIdx_x * 128 + threadIdx_x * 32 + blockIdx_y * 4 + threadIdx_y] = T.float32(0)\n",
            "            for ki, kj in T.grid(7, 7):\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                out_1[b * 2048 + c * 512 + blockIdx_x * 128 + threadIdx_x * 32 + blockIdx_y * 4 + threadIdx_y] = out_1[b * 2048 + c * 512 + blockIdx_x * 128 + threadIdx_x * 32 + blockIdx_y * 4 + threadIdx_y] + padded_inp_1[b * 3344 + c * 836 + blockIdx_x * 152 + threadIdx_x * 38 + ki * 38 + blockIdx_y * 4 + threadIdx_y + kj] * W_1[c * 49 + ki * 7 + kj]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [inp, ker, out], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE2DD12GVSoz",
        "outputId": "058c4a64-adf3-47c8-834e-d4c7a33f60bf",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ece5545/a3-NamanMakkar\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.9.16, pytest-7.2.2, pluggy-1.0.0\n",
            "rootdir: /content/drive/MyDrive/ece5545/a3-NamanMakkar\n",
            "plugins: anyio-3.6.2\n",
            "collected 1357 items                                                           \u001b[0m\n",
            "\n",
            "tests/test_dwsp_2dconv_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [  3%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [  8%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 13%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 19%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 24%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 29%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 34%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 40%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 45%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 50%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 56%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 61%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 66%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 72%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 77%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 82%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 87%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 93%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 98%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                      [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[20] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 20\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 20x speed-up failed: TVM Time: 2.54622e-03s TorchTime: 2.68546e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0025462199998855795 * 20.0) <= 0.026854620999984036\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[30] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 30\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 30x speed-up failed: TVM Time: 2.41234e-03s TorchTime: 2.72954e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002412338000112868 * 30.0) <= 0.02729542799988849\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[40] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 40\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 40x speed-up failed: TVM Time: 2.44032e-03s TorchTime: 2.95511e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0024403219999840076 * 40.0) <= 0.029551125000125467\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[50] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 50\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 50x speed-up failed: TVM Time: 2.35712e-03s TorchTime: 2.62700e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0023571209999317944 * 50.0) <= 0.02627000699999371\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[60] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 60\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 60x speed-up failed: TVM Time: 2.40393e-03s TorchTime: 2.94922e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0024039339998580544 * 60.0) <= 0.029492189999928087\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[70] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 70\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 70x speed-up failed: TVM Time: 2.34483e-03s TorchTime: 2.79223e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002344833000051949 * 70.0) <= 0.027922295000053055\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[80] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 80\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 80x speed-up failed: TVM Time: 2.38018e-03s TorchTime: 2.69202e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002380184999992707 * 80.0) <= 0.026920197999970696\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[90] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 90\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 90x speed-up failed: TVM Time: 2.58953e-03s TorchTime: 2.74215e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0025895349999700557 * 90.0) <= 0.02742152900009387\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[100] ____________________________\u001b[0m\n",
            "\n",
            "execution_number = 100\n",
            "\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.size()), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 100x speed-up failed: TVM Time: 3.50202e-03s TorchTime: 2.67375e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.003502024999988862 * 100.0) <= 0.026737542000091707\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[20]\u001b[0m - AssertionError: 20x speed-up failed: TVM Time: 2.54622e-03s TorchTime: 2.68...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[30]\u001b[0m - AssertionError: 30x speed-up failed: TVM Time: 2.41234e-03s TorchTime: 2.72...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[40]\u001b[0m - AssertionError: 40x speed-up failed: TVM Time: 2.44032e-03s TorchTime: 2.95...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[50]\u001b[0m - AssertionError: 50x speed-up failed: TVM Time: 2.35712e-03s TorchTime: 2.62...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[60]\u001b[0m - AssertionError: 60x speed-up failed: TVM Time: 2.40393e-03s TorchTime: 2.94...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[70]\u001b[0m - AssertionError: 70x speed-up failed: TVM Time: 2.34483e-03s TorchTime: 2.79...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[80]\u001b[0m - AssertionError: 80x speed-up failed: TVM Time: 2.38018e-03s TorchTime: 2.69...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[90]\u001b[0m - AssertionError: 90x speed-up failed: TVM Time: 2.58953e-03s TorchTime: 2.74...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[100]\u001b[0m - AssertionError: 100x speed-up failed: TVM Time: 3.50202e-03s TorchTime: 2.6...\n",
            "\u001b[31m================== \u001b[31m\u001b[1m9 failed\u001b[0m, \u001b[32m1348 passed\u001b[0m\u001b[31m in 637.70s (0:10:37)\u001b[0m\u001b[31m ==================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_dwsp_2dconv_gpu.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zqbo2VEVSo0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
