{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eGZIh3o1xch"
   },
   "source": [
    "# Depthwise-seperable 2D Convolution on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD2GHA5WVSow"
   },
   "source": [
    "## 1. Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnmfRsiBVSow"
   },
   "outputs": [],
   "source": [
    "# Mount google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rR5CmYuCVSox"
   },
   "outputs": [],
   "source": [
    "# Make sure your token is stored in a txt file at the location below.\n",
    "# This way there is no risk that you will push it to your repo\n",
    "# Never share your token with anyone, it is basically your github password!\n",
    "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
    "    token = f.readline().strip()\n",
    "# Use another file to store your github username    \n",
    "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
    "    handle = f.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZHBLuQfVSox"
   },
   "outputs": [],
   "source": [
    "# Clone your github repo\n",
    "YOUR_TOKEN = token\n",
    "YOUR_HANDLE = handle\n",
    "BRANCH = \"main\"\n",
    "\n",
    "%mkdir /content/gdrive/MyDrive/ece5545\n",
    "%cd /content/gdrive/MyDrive/ece5545\n",
    "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
    "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
    "!git checkout {BRANCH}\n",
    "!git pull\n",
    "%cd /content/gdrive/MyDrive/ece5545\n",
    "\n",
    "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfJNPVatVSox"
   },
   "outputs": [],
   "source": [
    "# This extension reloads all imports before running each cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7Bztq-VVSoy"
   },
   "outputs": [],
   "source": [
    "!ls {PROJECT_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EghxXWHSVyZR"
   },
   "source": [
    "## 2 Install TVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Phf10Wb1VxoB"
   },
   "outputs": [],
   "source": [
    "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1dTOTtqVSoy"
   },
   "source": [
    "## 3. Implement `make_dwsp_conv2d_gpu_scheduler` function in `src.ops`\n",
    "\n",
    "In that function, you are required to implemented 2D convolution and use TVM to optimize it.\n",
    "Please use zero padding and unit stride. \n",
    "You can assume kernel size to be an odd number.\n",
    "The padding will equals to kernel size minus ones.\n",
    "In this case, the output image will preserve the input image dimension.\n",
    "\n",
    "The `make_dwsp_conv2d_gpu_scheduler` takes following arguments:\n",
    "1. Batch size $B$;\n",
    "2. Input channel size $C$;\n",
    "3. Input image height $H$;\n",
    "4. Input image width $W$;\n",
    "5. Output number of channels $O$;\n",
    "6. Kernel size $K$\n",
    "\n",
    "You should return both the TVM scheduler and the TVM opterator for \n",
    "1. Input tensor $x$ with size (B, C, H, W)\n",
    "2. Input kernel weight $y$ with size (O, 1, K, K)\n",
    "3. Output $out$ with size (B, O, H, W)\n",
    "\n",
    "The scheduler should be able to used to build a function with signature $func(x, y, out)$. \n",
    "Please see the following cells the usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rbp2mmTVSoz"
   },
   "outputs": [],
   "source": [
    "import tvm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "# Adding assignment 3 to the system path\n",
    "# Make sure this matches your git directory\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "from src.ops import make_dwsp_conv2d_gpu_scheduler\n",
    "\n",
    "B = 3\n",
    "C = 4\n",
    "H = 16\n",
    "W = 32\n",
    "K = 7\n",
    "dtype = 'float32'\n",
    "a_np = np.random.rand(B, C, H, W).astype(dtype)\n",
    "w_np = np.random.rand(C, 1, K, K).astype(dtype)\n",
    "\n",
    "s, inp, ker, out = make_dwsp_conv2d_gpu_scheduler(B, C, H, W, K) \n",
    "func = tvm.build(s, [inp, ker, out], \"cuda\")\n",
    "\n",
    "dev = tvm.cuda(0)\n",
    "a = tvm.nd.array(a_np, dev)\n",
    "w = tvm.nd.array(w_np, dev)\n",
    "b = tvm.nd.array(np.zeros((B, O, H, W), dtype), dev)\n",
    "func(a, w, b)\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
    "\n",
    "print(\"Output:\", b)\n",
    "print(f\"2DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtM-xfNHVSoz"
   },
   "outputs": [],
   "source": [
    "print(tvm.lower(s, [inp, ker, out], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QE2DD12GVSoz",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd {PROJECT_ROOT}\n",
    "!python -m pytest tests/test_dwsp_2dconv_gpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Zqbo2VEVSo0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5-conv2d_dw_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
